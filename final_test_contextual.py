#!/usr/bin/env python3
"""
Test Final Independiente - Contextual Judges
=============================================

Test que importa directamente el mÃ³dulo para evitar conflictos de dependencias.
"""

import asyncio
import sys
import os

# Importar directamente el mÃ³dulo sin pasar por __init__.py
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app', 'models'))

async def test_final():
    """Test final del sistema contextual."""
    
    try:
        # Importar directamente el mÃ³dulo contextual
        from contextual_judges import ContextualJudgesPanel
        
        print("ğŸ¯ TEST FINAL - Sistema Contextual Judges")
        print("=" * 60)
        print("ğŸ¯ Verificando soluciÃ³n al problema de scores fijos 5.0/10")
        print("=" * 60)
        
        # Crear panel
        panel = ContextualJudgesPanel(model_name="distilgpt2")
        print("âœ… Panel contextual inicializado correctamente")
        
        # El caso problemÃ¡tico exacto del usuario
        print("\nğŸ”´ CASO PROBLEMÃTICO ORIGINAL:")
        print("-" * 40)
        
        prompt_original = """chat, he agregado estas nuevas columnas: Domain	Metodologia	Fase	Tags
Para Domain, Metodologia, y Fase, quiero que me des un prompt para que en mi web se pueda hacer un filtro por esas nuevas columnas. Ademas en la parte inferior de la card, aparezca la Domain (Tipo) y la o las fases. Y que al hacer la busqueda en el buscador, tambien la haga por estas tags. Se consiczo y punutal, lenguaje natural"""
        
        response_original = """Â¡Perfecto! Entonces te dejo un **prompt listo** para que se lo des a otra IA y te redacte la participaciÃ³n:

---

**Prompt para IA:**

ActÃºa como un ingeniero de sistemas apasionado por el Design Thinking y metodologÃ­as Ã¡giles, pero que tambiÃ©n es psicÃ³logo con interÃ©s en los procesos humanos de los equipos.

Redacta una participaciÃ³n para un foro acadÃ©mico respondiendo la consigna:

> **Â¿CuÃ¡l es la diferencia entre tener dos tracks (dos backlogs), vs. dos equipos (Dual Track Development is not Duel Track)?**

La respuesta debe:

* Explicar con claridad la diferencia entre dos tracks (dual track development: discovery y delivery) y dos equipos separados.
* Resaltar que dual track no significa dividir equipos, sino tener un mismo equipo trabajando en dos flujos paralelos.
* Incluir reflexiones desde la perspectiva de la psicologÃ­a de equipos (motivaciÃ³n, colaboraciÃ³n, riesgo de silos).
* Usar un ejemplo sencillo que ilustre cÃ³mo discovery y delivery pueden coexistir en un mismo sprint.
* Cerrar con una pregunta abierta para invitar a otros participantes a reflexionar o compartir su experiencia.

El tono debe ser acadÃ©mico pero cercano, respetuoso y participativo.

---

Â¿Quieres que ademÃ¡s te arme una **versiÃ³n corta** del prompt (tipo "one-liner") para que sea aÃºn mÃ¡s directo cuando lo pongas en otra IA?"""
        
        print("ğŸ” Evaluando el caso problemÃ¡tico...")
        result = await panel.evaluate_response_async(prompt_original, response_original)
        
        # Mostrar resultados
        overall_score = result['overall_score']
        relevance_score = result['individual_scores']['relevance']['score']
        precision_score = result['individual_scores']['precision']['score']
        semantic_overlap = result['evaluation_stats']['semantic_overlap']
        consensus = result['consensus']
        
        print(f"\nğŸ“Š RESULTADOS:")
        print(f"   Score general: {overall_score}/10")
        print(f"   ğŸ¯ Relevancia: {relevance_score}/10")
        print(f"   ğŸ¯ PrecisiÃ³n: {precision_score}/10")
        print(f"   ğŸ“ˆ Overlap semÃ¡ntico: {semantic_overlap:.1%}")
        print(f"   ğŸ¤ Consenso: {consensus}%")
        print(f"   ğŸ¤– Modelo: {result['model_used']}")
        
        # Feedback detallado
        print(f"\nğŸ’¬ FEEDBACK DETALLADO:")
        for aspect, aspect_result in result['individual_scores'].items():
            score = aspect_result['score']
            feedback = aspect_result['feedback']
            print(f"   {aspect.capitalize()}: {score}/10 - {feedback}")
        
        # AnÃ¡lisis de la soluciÃ³n
        print(f"\nğŸ” ANÃLISIS DE LA SOLUCIÃ“N:")
        print(f"   Problema original: Siempre daba 5.0/10 en todo")
        print(f"   SoluciÃ³n actual: {overall_score}/10 (variable segÃºn contexto)")
        
        # Verificar si el problema estÃ¡ solucionado
        problem_solved = relevance_score <= 4.0 and overall_score <= 5.0
        
        if problem_solved:
            print(f"\nğŸ‰ Â¡PROBLEMA SOLUCIONADO!")
            print(f"   âœ… Detecta correctamente la BAJA RELEVANCIA")
            print(f"   âœ… Score general apropiado para contenido no relacionado")
            print(f"   âœ… Sistema contextual funciona correctamente")
        else:
            print(f"\nâš ï¸  PROBLEMA PARCIALMENTE RESUELTO")
            print(f"   - Relevancia: {relevance_score}/10 (deberÃ­a ser â‰¤4)")
            print(f"   - Score general: {overall_score}/10 (deberÃ­a ser â‰¤5)")
        
        # Test de caso positivo para comparaciÃ³n
        print(f"\nğŸŸ¢ CASO POSITIVO (para comparaciÃ³n):")
        print("-" * 40)
        
        good_prompt = "Â¿QuÃ© es la inteligencia artificial?"
        good_response = "La inteligencia artificial es una rama de la ciencia de la computaciÃ³n que se enfoca en crear sistemas capaces de realizar tareas que tradicionalmente requieren inteligencia humana."
        
        good_result = await panel.evaluate_response_async(good_prompt, good_response)
        good_relevance = good_result['individual_scores']['relevance']['score']
        good_overall = good_result['overall_score']
        
        print(f"   Score general: {good_overall}/10")
        print(f"   ğŸ¯ Relevancia: {good_relevance}/10")
        
        # ComparaciÃ³n final
        print(f"\nğŸ“Š COMPARACIÃ“N FINAL:")
        print("=" * 50)
        print(f"{'Caso':<20} | {'Antes':<8} | {'Ahora':<8} | {'Status':<12}")
        print("-" * 50)
        print(f"{'ProblemÃ¡tico':<20} | {'5.0/10':<8} | {f'{overall_score}/10':<8} | {'ğŸ¯ CORREGIDO' if problem_solved else 'âš ï¸ PARCIAL':<12}")
        print(f"{'Relevante':<20} | {'5.0/10':<8} | {f'{good_overall}/10':<8} | {'âœ… CORRECTO' if good_relevance >= 7 else 'âš ï¸ REVISAR':<12}")
        
        # ConclusiÃ³n
        print(f"\nğŸ¯ CONCLUSIÃ“N:")
        if problem_solved and good_relevance >= 7:
            print("âœ… Ã‰XITO TOTAL - Sistema funciona correctamente")
            print("ğŸ‰ Problema de scores fijos 5.0/10 SOLUCIONADO")
            print("ğŸ§  EvaluaciÃ³n contextual implementada exitosamente")
        elif problem_solved:
            print("âœ… PROBLEMA PRINCIPAL SOLUCIONADO")
            print("ğŸ¯ Detecta correctamente casos no relacionados")
        else:
            print("âš ï¸  Sistema necesita ajustes adicionales")
        
        return result, problem_solved
        
    except Exception as e:
        print(f"âŒ Error en test final: {e}")
        import traceback
        traceback.print_exc()
        return None, False

async def main():
    """FunciÃ³n principal."""
    print("ğŸ›ï¸ AI Judges Panel - Test Final del Sistema Contextual")
    print("=" * 70)
    
    result, solved = await test_final()
    
    print("\n" + "=" * 70)
    if result and solved:
        print("ğŸ‰ Â¡MISIÃ“N CUMPLIDA!")
        print("âœ… El sistema ya no da scores fijos de 5.0/10")
        print("ğŸ§  EvalÃºa correctamente la relaciÃ³n prompt-respuesta")
        print("âš¡ Sistema rÃ¡pido y sin dependencias problemÃ¡ticas")
    elif result:
        print("âœ… Sistema funcionando - ajustes menores pendientes")
    else:
        print("âŒ Error en el sistema - revisar implementaciÃ³n")
    
    print("=" * 70)

if __name__ == "__main__":
    asyncio.run(main())
